<!DOCTYPE html>
<html>

<head>
    <title>Prompting in Vision</title>

    <style>
        body {
            width: 95%;
            margin: 0 auto;
            background-color: #f2f2f2;
            font-size: 18px; /* default 16px */
        }

        a:link {
            color: blue;
        }

        a:visited {
            color: blue;
        }

        a:hover {
            color: orange;
        }

        img {
            max-width: 100%;
            max-height: 100%;
        }

        td {
            text-align: left;
            padding-top: 5px;
            padding-bottom: 5px;
            padding-left: 15px;
            padding-right: 0px;
        }

        .row {
            content: "";
            clear: both;
            display: flex;
            flex-direction: row;
            justify-content: center;
            padding-bottom: 5px;
        }

        .column {
            float: left;
            width: 15%;
            padding: 5px;
        }

        .container {
            text-align: center;
            background-color: #ffffff;
            padding: 15px;
            margin: 20px;
        }

        .text-content {
            text-align: left;
        }

        @media only screen and (max-width: 768px) {
            .row {
                display: flex;
                flex-direction: column;
                justify-content: center;
            }

            .column {
                float: left;
                width: 100%;
                padding: 0px;
                margin-bottom: 10px;
            }
        }
    </style>

    <meta charset="UTF-8">
    <meta name="description" content="CVPR 2023 Tutorial on Prompting in Vision">
    <meta name="keywords" content="CVPR, Computer Vision, Prompting">
    <meta name="author" content="Kaiyang Zhou et al.">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

<div class="container">
    <h2>CVPR 2023 Tutorial on <i>Prompting in Vision</i></h2>
    <h2>19 June 2023, 9AM-12PM</h2>
    <h3>West 223-224, Vancouver Convention Centre</h3>
    <img src="images/cvpr_banner.png" width="50%" alt="CVPR2023">
</div>

<div class="container">
    <h2>Tutorial lecturers</h2>

    <div class="row">
        <div class="column">
            <a href="https://kaiyangzhou.github.io/">
                <img src="people/ky.png" alt="Kaiyang Zhou">
                <div>Kaiyang Zhou<br>NTU</div>
            </a>
        </div>
        <div class="column">
            <a href="https://liuziwei7.github.io/">
                <img src="people/ziwei.jpg" alt="Ziwei Liu">
                <div>Ziwei Liu<br>NTU</div>
            </a>
        </div>
        <div class="column">
            <a href="http://web.mit.edu/phillipi/">
                <img src="people/phillip.jpeg" alt="Phillip Isola">
                <div>Phillip Isola<br>MIT</div>
            </a>
        </div>
        <div class="column">
            <a href="https://hjbahng.github.io/">
                <img src="people/hyojin.png" alt="Hyojin Bahng">
                <div>Hyojin Bahng<br>MIT</div>
            </a>
        </div>
    </div>

    <div class="row">
        <div class="column">
            <a href="https://people.csail.mit.edu/ludwigs/">
                <img src="people/ludwig.jpg" alt="Ludwig Schmidt">
                <div>Ludwig Schmidt<br>University of Washington</div>
            </a>
        </div>
        <div class="column">
            <a href="https://sarahpratt.github.io/">
                <img src="people/sarah.jpg" alt="Sarah Pratt">
                <div>Sarah Pratt<br>University of Washington</div>
            </a>
        </div>
        <div class="column">
            <a href="https://dennyzhou.github.io/">
                <img src="people/denny.jpeg" alt="Denny Zhou">
                <div>Denny Zhou<br>Google Brain</div>
            </a>
        </div>
    </div>
</div>

<div class="container">
    <h2>Overview</h2>
    <div class="text-content">
         <p>Originating from natural language processing, the new paradigm of prompting has recently swept through the computer vision community, bringing disruptive changes to various computer vision applications, such as image recognition and image generation. In comparison to the traditional fixed-once-learned architecture, like a linear classifier trained to recognize a specific set of categories, prompting offers greater flexibility and more opportunities for novel applications. It allows the model to perform new tasks, such as recognizing new categories, by tuning textual instructions or modifying a small number of parameters in the model's input space while keeping the majority of the pre-trained parameters untouched. This paradigm significantly pushes conversational human-AI interaction to unprecedented levels. Within a short period of time, the effectiveness of prompting has been demonstrated in a wide range of problem domains, including image classification, object detection, image generation and editing, video analytics, and robot control. In this tutorial, our aim is to provide a comprehensive background on prompting by building connections between research in computer vision and natural language processing. We will also review the latest advances in using prompting to tackle computer vision problems.</p>
    </div>
</div>

<div class="container">
    <h2>Schedule</h2>
    <table>
        <tr>
            <td>09:00 am - 09:10 am</td>
            <td>Opening remarks, by <a href="https://kaiyangzhou.github.io/">Kaiyang Zhou</a></td>
        </tr>

        <tr>
            <td>09:10 am - 09:50 am</td>
            <td>Prompting in visual intelligence and generation, by <a href="https://kaiyangzhou.github.io/">Kaiyang Zhou</a> & <a href="https://liuziwei7.github.io/">Ziwei Liu</a> [<a href="slides/cvpr23/lecture-1a.pdf">slides-a</a> & <a href="https://youtu.be/fIoeCI3gH94">video-a</a>, <a href="slides/cvpr23/lecture-1b.pdf">slides-b</a> & <a href="https://youtu.be/IT9aOmK2AkQ">video-b</a>]</td>
        </tr>

        <tr>
            <td>09:50 am - 10:30 am</td>
            <td>Teaching language models to reason, by <a href="https://dennyzhou.github.io/">Denny Zhou</a> [<a href="http://dennyzhou.github.io/Teach-LLMs-to-Reason-6-2023.pdf">slides</a>]</td>
        </tr>

        <tr>
            <td>10:30 am - 10:40 am</td>
            <td>Coffee break</td>
        </tr>

        <tr>
            <td>10:40 am - 11:20 am</td>
            <td>Visual prompting, by <a href="https://hjbahng.github.io/">Hyojin Bahng</a> & <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> [<a href="slides/cvpr23/lecture-3.pdf">slides</a>]</td>
        </tr>

        <tr>
            <td>11:20 am - 12:00 pm</td>
            <td>Improved model adaptation via weight interpolation and prompt generation, by <a href="https://sarahpratt.github.io/">Sarah Pratt</a> & <a href="https://people.csail.mit.edu/ludwigs/">Ludwig Schmidt</a> [<a href="https://sarahpratt.github.io/assets/pratt_cvpr2023.pdf">slides-a</a> & <a href="https://youtu.be/mFB3UPzcfpI">video-a</a>, <a href="https://youtu.be/imXyc1wYWV0">video-b</a>]</td>
        </tr>
    </table>
</div>

<div class="container">
    <h2>Photos</h2>
    <h3>Big thanks to everyone showing up (in-person & online) at our tutorial!</h3>
    
    <a href="images/cvpr23/image001.jpg">
        <img src="images/cvpr23/image001.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image002.jpg">
        <img src="images/cvpr23/image002.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image003.jpeg">
        <img src="images/cvpr23/image003.jpeg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image004.jpg">
        <img src="images/cvpr23/image004.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image005.jpg">
        <img src="images/cvpr23/image005.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image006.jpg">
        <img src="images/cvpr23/image006.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image007.jpg">
        <img src="images/cvpr23/image007.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image008.jpg">
        <img src="images/cvpr23/image008.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image009.jpg">
        <img src="images/cvpr23/image009.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image010.jpg">
        <img src="images/cvpr23/image010.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image011.jpg">
        <img src="images/cvpr23/image011.jpg" width="300" height="200">
    </a>

    <a href="images/cvpr23/image012.jpg">
        <img src="images/cvpr23/image012.jpg" width="300" height="200">
    </a>
</div>

<div class="container">
    <h2>Contact</h2>
    <div class="text-content">
        <p>Please contact <a href="https://kaiyangzhou.github.io/">Kaiyang Zhou</a> for general inquiries.</p>
    </div>
</div>

<br>

</body>
</html>
